import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from numpy import nan as NA
import matplotlib.pyplot as plt
import math
from pandas.tseries.offsets import Day,MonthEnd,BDay
import os
from scipy import stats
from scipy.stats import percentileofscore
from scipy.stats import rankdata, mstats, zscore
from sklearn.preprocessing import QuantileTransformer
from tqdm import tqdm


def setting_up():

    #è®¾ç½®ç”»å›¾å­—ä½“ä¸ºé»‘ä½“
    plt.rcParams['font.sans-serif'] = 'simhei'

    #æ­£å¸¸æ˜¾ç¤ºè´Ÿå·åœ¨å›¾é‡Œ
    plt.rcParams['axes.unicode_minus']=False

    return
setting_up()


class ETF_Strategy():

    def __init__(self,End_Date,Code_List,Begin_Date,Data_Path_List):

        self.Code_List=Code_List

        self.End_Date=End_Date

        self.Begin_Date=Begin_Date

        self.Data_Path_List=Data_Path_List

    def second_order_momentum_factor(window_1=20,window_2=10,window_3=5):
        # è®¡ç®—å› å­çš„å‡½æ•°
        def calculate_factor(df,window_1,window_2,window_3):

            # ç¡®ä¿æ•°æ®æŒ‰ç…§æ—¶é—´æ’åº
            df = df.sort_values('time')
            # è®¡ç®—è¿‡å»Window1æ—¥çš„å‡ä»·
            df['MA'] = df['close'].rolling(window=window_1).mean()

            # è®¡ç®—æœ€æ–°ä¸€æœŸæ”¶ç›˜ä»·ä¸è¿‡å»ä¸€æ®µæ—¶é—´å‡ä»·çš„åç¦»åº¦
            df['Deviation'] = (df['close'] - df['MA']) / df['MA']

            # è®¡ç®—ï¼ˆæœ€æ–°ä¸€æœŸæ”¶ç›˜ä»·ä¸è¿‡å»ä¸€æ®µæ—¶é—´å‡ä»·çš„åç¦»åº¦ï¼‰-è¿‡å»window2æ—¥çš„ï¼ˆæœ€æ–°ä¸€æœŸæ”¶ç›˜ä»·ä¸è¿‡å»ä¸€æ®µæ—¶é—´å‡ä»·çš„åç¦»åº¦ï¼‰ 
            df['Deviation_Diff'] = df['Deviation'] - df['Deviation'].shift(window_2)

            # å°†ä¸Šè¿°çš„ç»“æœè¿›è¡ŒæŒ‡æ•°åŠ æƒç§»åŠ¨å¹³å‡ï¼Œå¹³å‡æ—¥æ•°é‡ä¸ºWindowæ—¥
            df['factor'] = df['Deviation_Diff'].ewm(span=window_3).mean()

            return df

        # è®¡ç®—æ‰€æœ‰è‚¡ç¥¨çš„å› å­
        def calculate_all_factors(price_path,window_1,window_2,window_3):
            # è·å–æ‰€æœ‰è‚¡ç¥¨ä»£ç 
            all_data_file = os.listdir(price_path)
            # åˆ›å»ºä¸€ä¸ªç©ºçš„DataFrameæ¥ä¿å­˜æ‰€æœ‰è‚¡ç¥¨çš„å› å­
            all_factors = pd.DataFrame()

            # éå†æ¯ä¸€ä¸ªè‚¡ç¥¨ä»£ç ï¼Œè®¡ç®—å…¶å› å­ï¼Œå¹¶æ·»åŠ åˆ°all_factorsä¸­
            for code in all_data_file:
                try:
                    df=pd.read_csv(price_path+'\\'+code)
                    #å¯¹æ¯ä¸€ä¸ªæ•°æ®éƒ½è®¡ç®—ç¬¬ä¸€æ­¥å®šä¹‰çš„ç®—æ³•
                    factor = calculate_factor(df,window_1,window_2,window_3)
                    all_factors = all_factors.append(factor)
                except:
                    print(code+'å‡ºç°é”™è¯¯è·³è¿‡')

            return all_factors

        # å»é™¤å¼‚å¸¸å€¼å¹¶è¿›è¡Œæ ‡å‡†åŒ–
        def winsorize_and_standardize(df):
            # ä½¿ç”¨æ ‡å‡†å·®æ–¹æ³•å¤„ç†æç«¯å€¼
            def limit_to_std(x):
                # è®¡ç®—å¹³å‡å€¼å’Œæ ‡å‡†å·®
                mean = x.mean()
                std = x.std()
                # å°†è¶…è¿‡3å€æ ‡å‡†å·®çš„å€¼è®¾ä¸º3å€æ ‡å‡†å·®
                x = x.apply(lambda v: min(max(v, mean - 3 * std), mean + 3 * std))
                return x
            
            # åº”ç”¨limit_to_stdå‡½æ•°å¤„ç†æ¯ä¸ªæ—¶é—´ç»„çš„å› å­å€¼
            df['standard_factor'] = df['factor'].groupby(df['time']).transform(limit_to_std)
            
            # ä½¿ç”¨zscoreæ–¹æ³•è¿›è¡Œæ ‡å‡†åŒ–
            df['standard_factor'] = df.groupby('time')['standard_factor'].transform(zscore)
            
            result = df[['time','thscode', 'factor', 'standard_factor']]

            return result

        #è®¾ç½®è®¡ç®—å› å­çš„æ•°æ®è·¯å¾„
        price_path=r'D:\é‡åŒ–äº¤æ˜“æ„å»º\å¸‚åœºæ•°æ®åº“\æ•°æ®åº“\åŒèŠ±é¡ºETFè·Ÿè¸ªæŒ‡æ•°é‡ä»·æ•°æ®'
        # è®¡ç®—æ‰€æœ‰è‚¡ç¥¨çš„å› å­,å¹¶ä¸”åˆå¹¶åœ¨ä¸€ä¸ªè¡¨ä¸­
        all_factors = calculate_all_factors(price_path,window_1,window_2,window_3)
        all_factors=all_factors.dropna()

        # å¯¹å› å­è¿›è¡Œå»é™¤å¼‚å¸¸å€¼å’Œæ ‡å‡†åŒ–æ“ä½œ
        all_factors = winsorize_and_standardize(all_factors)

        # å°†ç»“æœä¿å­˜åˆ°CSVæ–‡ä»¶ä¸­
        filename='second_order_momentum_factor'+str(window_1)+'D_'+str(window_2)+'D_'+str(window_3)+'D'

        all_factors.to_csv(r"D:\é‡åŒ–äº¤æ˜“æ„å»º\ETFè½®åŠ¨ç­–ç•¥\ETFè½®åŠ¨ç­–ç•¥ç¨‹åº\ETFå› å­åº“\æœ‰æ•ˆå› å­"+"\\"+filename+'.csv')

        return all_factors

    def Second_Order_Momentum_Factor(Code, Window1, Window2, Window):
        # è®¾ç½®æ•°æ®è·¯å¾„
        path = "C:\\Users\\Wesle\\Desktop\\é‡åŒ–äº¤æ˜“æ„å»º\\å¸‚åœºæ•°æ®åº“\\æ•°æ®åº“\\åŒèŠ±é¡ºETFè·Ÿè¸ªæŒ‡æ•°é‡ä»·æ•°æ®\\"
        file = os.path.join(path, "{}.csv".format(Code))

        # è¯»å–æ•°æ®  
        data = pd.read_csv(file)

        # ç¡®ä¿æ•°æ®æ˜¯æŒ‰æ—¥æœŸæ’åºçš„
        data['time'] = pd.to_datetime(data['time'])
        data = data.sort_values('time')
        data.set_index('time', inplace=True)

        # è®¡ç®—è¿‡å»Window1æ—¥çš„å‡ä»·
        data['MA'] = data['close'].rolling(window=Window1).mean()

        # è®¡ç®—æœ€æ–°ä¸€æœŸæ”¶ç›˜ä»·ä¸è¿‡å»ä¸€æ®µæ—¶é—´å‡ä»·çš„åç¦»åº¦
        data['Deviation'] = (data['close'] - data['MA']) / data['MA']

        # è®¡ç®—ï¼ˆæœ€æ–°ä¸€æœŸæ”¶ç›˜ä»·ä¸è¿‡å»ä¸€æ®µæ—¶é—´å‡ä»·çš„åç¦»åº¦ï¼‰-è¿‡å»window2æ—¥çš„ï¼ˆæœ€æ–°ä¸€æœŸæ”¶ç›˜ä»·ä¸è¿‡å»ä¸€æ®µæ—¶é—´å‡ä»·çš„åç¦»åº¦ï¼‰ 
        data['Deviation_Diff'] = data['Deviation'] - data['Deviation'].shift(Window2)

        # å°†ä¸Šè¿°çš„ç»“æœè¿›è¡ŒæŒ‡æ•°åŠ æƒç§»åŠ¨å¹³å‡ï¼Œå¹³å‡æ—¥æ•°é‡ä¸ºWindowæ—¥
        data['Second_Order_Momentum'] = data['Deviation_Diff'].ewm(span=Window).mean()

        # å°†ç»“æœåˆ—é‡å‘½åä¸º '<Code>äºŒé˜¶åŠ¨é‡åˆ†æ•°'
        data.rename(columns={'Second_Order_Momentum': '{}äºŒé˜¶åŠ¨é‡åˆ†æ•°'.format(Code)}, inplace=True)

        # è¿”å›åªåŒ…å«äºŒé˜¶åŠ¨é‡åˆ†æ•°çš„DataFrame
        return data[['{}äºŒé˜¶åŠ¨é‡åˆ†æ•°'.format(Code)]]
    
    #åŠ¨é‡å› å­
    def Momentum_Term_Spread_Factor(code, window1, window2):
        # è¯»å–æ•°æ®
        filepath = f"C:/Users/Wesle/Desktop/é‡åŒ–äº¤æ˜“æ„å»º/å¸‚åœºæ•°æ®åº“/æ•°æ®åº“/åŒèŠ±é¡ºETFè·Ÿè¸ªæŒ‡æ•°é‡ä»·æ•°æ®/{code}.csv"
        data = pd.read_csv(filepath)
        
        # ç¡®ä¿æ•°æ®æ˜¯æŒ‰æ—¶é—´å‡åºæ’åˆ—çš„
        data = data.sort_values(by='time')

        # è®¡ç®—é•¿æœŸåŠ¨é‡å’ŒçŸ­æœŸåŠ¨é‡
        data['long_term_momentum'] = (data['close'] - data['close'].shift(window1)) / data['close'].shift(window1)
        data['short_term_momentum'] = (data['close'] - data['close'].shift(window2)) / data['close'].shift(window2)

        # è®¡ç®—åŠ¨é‡æœŸé™å·®å› å­
        data[code + 'åŠ¨é‡æœŸé™å·®åˆ†æ•°'] = data['long_term_momentum'] - data['short_term_momentum']

        # è¿”å›ç»“æœï¼ŒåªåŒ…å«æ—¥æœŸå’ŒåŠ¨é‡æœŸé™å·®å› å­
        return data.set_index('time')[[code + 'åŠ¨é‡æœŸé™å·®åˆ†æ•°']]

    def Caculate_Momentum_Term_Spread_Score(End_Date,window1=150,window2=75):
        # å®šä¹‰ä¸€ä¸ªå‡½æ•°è®¡ç®—å•ä¸ªè‚¡ç¥¨çš„åŠ¨é‡æœŸé™å·®å› å­
        #ç»è¿‡æµ‹è¯•75 25çš„å‚æ•°æœ€å¥½ï¼Œä¸”è¿™ä¸ªå› å­æœ‰æ•ˆ
        def Momentum_Term_Spread_Factor(code, window1, window2):
            # æŒ‡å®šè‚¡ç¥¨æ•°æ®æ–‡ä»¶çš„è·¯å¾„
            filepath = f"C:/Users/Wesle/Desktop/é‡åŒ–äº¤æ˜“æ„å»º/å¸‚åœºæ•°æ®åº“/æ•°æ®åº“/åŒèŠ±é¡ºETFè·Ÿè¸ªæŒ‡æ•°é‡ä»·æ•°æ®/{code}.csv"
            # è¯»å–è‚¡ç¥¨æ•°æ®
            data = pd.read_csv(filepath)
            # æŒ‰æ—¶é—´æ’åº
            data = data.sort_values(by='time')

            # è®¡ç®—é•¿æœŸåŠ¨é‡
            data['long_term_momentum'] = (data['close'] - data['close'].shift(window1)) / data['close'].shift(window1)
            # è®¡ç®—çŸ­æœŸåŠ¨é‡
            data['short_term_momentum'] = (data['close'] - data['close'].shift(window2)) / data['close'].shift(window2)
            # è®¡ç®—åŠ¨é‡æœŸé™å·®å› å­
            data['Momentum_Term_Spread'] = data['long_term_momentum'] - data['short_term_momentum']

            # è¿”å›å¸¦æœ‰åŠ¨é‡æœŸé™å·®å› å­çš„æ•°æ®
            return data.set_index('time')[['Momentum_Term_Spread']]

        # æŒ‡å®šé•¿æœŸå’ŒçŸ­æœŸåŠ¨é‡çš„çª—å£æœŸ
        window1 = window1
        window2 = window2

        # æŒ‡å®šè¦æå–å› å­å€¼çš„æ—¥æœŸ
        date = End_Date

        # åˆ—å‡ºç›®å½•ä¸­çš„æ‰€æœ‰csvæ–‡ä»¶
        files = os.listdir('C:/Users/Wesle/Desktop/é‡åŒ–äº¤æ˜“æ„å»º/å¸‚åœºæ•°æ®åº“/æ•°æ®åº“/åŒèŠ±é¡ºETFè·Ÿè¸ªæŒ‡æ•°é‡ä»·æ•°æ®')

        # åˆå§‹åŒ–ä¸€ä¸ªç©ºçš„dataframeæ¥å­˜å‚¨æ‰€æœ‰è‚¡ç¥¨çš„å› å­å€¼
        factor_values = pd.DataFrame()

        for file in files:

            try:
                # è·å–è‚¡ç¥¨ä»£ç 
                code = file.rstrip('.csv')
                # è®¡ç®—è‚¡ç¥¨çš„åŠ¨é‡æœŸé™å·®å› å­
                factor = Momentum_Term_Spread_Factor(code, window1, window2)

                factor.index=pd.to_datetime(factor.index)
                # æå–æŒ‡å®šæ—¥æœŸçš„å› å­å€¼å¹¶æ·»åŠ åˆ°dataframeä¸­
                factor_value = factor.loc[date, 'Momentum_Term_Spread']

                factor_values.loc[code, 'Momentum_Term_Spread'] = factor_value

            except:

                print('å‡ºç°é”™è¯¯è·³è¿‡')

        # å¯¹å› å­å€¼è¿›è¡ŒWinsorizeå¤„ç†ä»¥ç§»é™¤å¼‚å¸¸å€¼
        factor_values['Momentum_Term_Spread'] = mstats.winsorize(factor_values['Momentum_Term_Spread'], limits=[0.01, 0.01])

        # ä½¿ç”¨z-scoreå¯¹å› å­å€¼è¿›è¡Œæ ‡å‡†åŒ–
        factor_values['Momentum_Term_Spread'] = zscore(factor_values['Momentum_Term_Spread'])

        return factor_values

    def Caculate_Second_Order_Momentum_Factor(End_Date):

        #å®šä¹‰ä¸€ä¸ªå‡½æ•°è®¡ç®—å•ä¸ªè‚¡ç¥¨çš„äºŒé˜¶åŠ¨é‡å› å­å€¼,ä»è®¡ç®—ç»“æœçœ‹è¿™æ˜¯ä¸€ä¸ªåè½¬å› å­

        def Second_Order_Momentum_Factor(Code, Window1, Window2, Window):
            # è®¾ç½®æ•°æ®è·¯å¾„
            path = "C:\\Users\\Wesle\\Desktop\\é‡åŒ–äº¤æ˜“æ„å»º\\å¸‚åœºæ•°æ®åº“\\æ•°æ®åº“\\åŒèŠ±é¡ºETFè·Ÿè¸ªæŒ‡æ•°é‡ä»·æ•°æ®\\"
            file = os.path.join(path, "{}.csv".format(Code))

            # è¯»å–æ•°æ®  
            data = pd.read_csv(file)

            # ç¡®ä¿æ•°æ®æ˜¯æŒ‰æ—¥æœŸæ’åºçš„
            data['time'] = pd.to_datetime(data['time'])
            data = data.sort_values('time')
            data.set_index('time', inplace=True)

            # è®¡ç®—è¿‡å»Window1æ—¥çš„å‡ä»·
            data['MA'] = data['close'].rolling(window=Window1).mean()

            # è®¡ç®—æœ€æ–°ä¸€æœŸæ”¶ç›˜ä»·ä¸è¿‡å»ä¸€æ®µæ—¶é—´å‡ä»·çš„åç¦»åº¦
            data['Deviation'] = (data['close'] - data['MA']) / data['MA']

            # è®¡ç®—ï¼ˆæœ€æ–°ä¸€æœŸæ”¶ç›˜ä»·ä¸è¿‡å»ä¸€æ®µæ—¶é—´å‡ä»·çš„åç¦»åº¦ï¼‰-è¿‡å»window2æ—¥çš„ï¼ˆæœ€æ–°ä¸€æœŸæ”¶ç›˜ä»·ä¸è¿‡å»ä¸€æ®µæ—¶é—´å‡ä»·çš„åç¦»åº¦ï¼‰ 
            data['Deviation_Diff'] = data['Deviation'] - data['Deviation'].shift(Window2)

            # å°†ä¸Šè¿°çš„ç»“æœè¿›è¡ŒæŒ‡æ•°åŠ æƒç§»åŠ¨å¹³å‡ï¼Œå¹³å‡æ—¥æ•°é‡ä¸ºWindowæ—¥
            data['Second_Order_Momentum'] = -(data['Deviation_Diff'].ewm(span=Window).mean())

            # å°†ç»“æœåˆ—é‡å‘½åä¸º '<Code>äºŒé˜¶åŠ¨é‡åˆ†æ•°'
            data.rename(columns={'Second_Order_Momentum': '{}äºŒé˜¶åŠ¨é‡åˆ†æ•°'.format(Code)}, inplace=True)

            # è¿”å›åªåŒ…å«äºŒé˜¶åŠ¨é‡åˆ†æ•°çš„DataFrame
            return data[['{}äºŒé˜¶åŠ¨é‡åˆ†æ•°'.format(Code)]]

        date=End_Date

        Window1=25

        Window2=10

        Window=5

        # åˆ—å‡ºç›®å½•ä¸­çš„æ‰€æœ‰csvæ–‡ä»¶
        files = os.listdir('C:/Users/Wesle/Desktop/é‡åŒ–äº¤æ˜“æ„å»º/å¸‚åœºæ•°æ®åº“/æ•°æ®åº“/åŒèŠ±é¡ºETFè·Ÿè¸ªæŒ‡æ•°é‡ä»·æ•°æ®')

        # åˆå§‹åŒ–ä¸€ä¸ªç©ºçš„dataframeæ¥å­˜å‚¨æ‰€æœ‰è‚¡ç¥¨çš„å› å­å€¼
        factor_values = pd.DataFrame()

        for file in files:

            try:
                # è·å–è‚¡ç¥¨ä»£ç 
                code = file.rstrip('.csv')
                # è®¡ç®—è‚¡ç¥¨çš„äºŒé˜¶åŠ¨é‡å› å­å€¼
                factor = Second_Order_Momentum_Factor(code, Window1, Window2, Window)
                # æå–æŒ‡å®šæ—¥æœŸçš„å› å­å€¼å¹¶æ·»åŠ åˆ°dataframeä¸­
                factor_value = factor.loc[date, '{}äºŒé˜¶åŠ¨é‡åˆ†æ•°'.format(code)]
                factor_values.loc[code, 'Second_Order_Momentum_Factor'] = factor_value
            except:

                print('å‡ºç°é”™è¯¯è·³è¿‡')

        # å¯¹å› å­å€¼è¿›è¡ŒWinsorizeå¤„ç†ä»¥ç§»é™¤å¼‚å¸¸å€¼
        factor_values['Second_Order_Momentum_Factor'] = mstats.winsorize(factor_values['Second_Order_Momentum_Factor'], limits=[0.01, 0.01])

        # ä½¿ç”¨z-scoreå¯¹å› å­å€¼è¿›è¡Œæ ‡å‡†åŒ–
        factor_values['Second_Order_Momentum_Factor'] = zscore(factor_values['Second_Order_Momentum_Factor'])

        # æ‰“å°æ‰€æœ‰è‚¡ç¥¨çš„å› å­å€¼
        return factor_values
   
    def Caculate_Information_Ratio_Factor(End_Date):

        def Caculate_Information_Ratio_Windway(Begin_Date, End_Date, Benchmark_Code='000906.SH'):

            def Get_ETF_Close_Price(code):

                filepath = "C:\\Users\\Wesle\\Desktop\\é‡åŒ–äº¤æ˜“æ„å»º\\å¸‚åœºæ•°æ®åº“\\æ•°æ®åº“\\åŒèŠ±é¡ºETFè·Ÿè¸ªæŒ‡æ•°é‡ä»·æ•°æ®"

                data = pd.read_csv(filepath + "\\" + code+".csv", index_col=[0])

                data.index = pd.to_datetime(data.index)

                Close_Price = data[["close"]]

                Close_Price.columns=[code]

                return Close_Price

            Code_List_Path="C:\\Users\\Wesle\\Desktop\\é‡åŒ–äº¤æ˜“æ„å»º\\å¸‚åœºæ•°æ®åº“\\æ•°æ®åº“"

            Name="åŒèŠ±é¡ºETFè·Ÿè¸ªæŒ‡æ•°ä»£ç åº“.xlsx"

            Code_List=pd.read_excel(Code_List_Path+"\\"+Name)

            Code_List=Code_List.loc[:,"è·Ÿè¸ªæŒ‡æ•°ä»£ç "].tolist()

            Benchmark = Get_ETF_Close_Price(Benchmark_Code)

            IRs = []

            for i in range(0, len(Code_List)):

                try:

                    ETF_Close_Price = Get_ETF_Close_Price(Code_List[i])

                    Combined_Data = pd.merge(ETF_Close_Price, Benchmark, right_index=True, left_index=True)

                    Combined_Data = Combined_Data.loc[Begin_Date:End_Date, :]

                    # è®¡ç®—åŒºé—´å†…çš„è¶…é¢æ”¶ç›Šç‡ä¸è¶…é¢æ³¢åŠ¨ç‡

                    Combined_Data_Total_Return = Combined_Data.iloc[-1, :] / Combined_Data.iloc[0, :] - 1

                    Days = len(Combined_Data.index)

                    # è®¡ç®—åŒºé—´å†…çš„å¹´åŒ–æ”¶ç›Šç‡

                    Annual_Return = ((1 + Combined_Data_Total_Return) ** (250 / Days)) - 1

                    Alpha_Annual_Return = Annual_Return[0] - Annual_Return[1]

                    # è®¡ç®—è·Ÿè¸ªè¯¯å·®

                    Combined_Data_Pct = Combined_Data / Combined_Data.shift(1) - 1

                    Daily_Error = Combined_Data_Pct.loc[:, Code_List[i]] - Combined_Data_Pct.loc[:, Benchmark_Code]

                    Error = Daily_Error.std()

                    N = 250 ** 0.5

                    Annual_Error=Error*N

                    IR = Alpha_Annual_Return / Annual_Error

                    IR = pd.DataFrame(IR, index=[Code_List[i]], columns=["Information_Ratio"])

                    IRs.append(IR)

                    print("Information_Ratioè®¡ç®—å®Œæˆåº¦ï¼š" + str(i / len(Code_List)))

                except:

                    print(Code_List[i] + " æŠ¥é”™")

            IRs = pd.concat(IRs, axis=0)

            return IRs

        def Get_Crowdy_Ratio(End_Date):

            Code_List_Path="C:\\Users\\Wesle\\Desktop\\é‡åŒ–äº¤æ˜“æ„å»º\\å¸‚åœºæ•°æ®åº“\\æ•°æ®åº“"

            Name="åŒèŠ±é¡ºETFè·Ÿè¸ªæŒ‡æ•°ä»£ç åº“.xlsx"

            Code_List=pd.read_excel(Code_List_Path+"\\"+Name)

            Code_List=Code_List.loc[:,"è·Ÿè¸ªæŒ‡æ•°ä»£ç "].tolist()

            # è®¡ç®—åŒºé—´ç§»åŠ¨å¹³å‡æ•°çš„åŒºé—´åˆ†ä½å€¼

            def Get_Last_Percentile_Score(code,End_Date, Rolling_Mean=25):

                def Get_Index_Free_Turn_Data(code):
                    filepath = "C:\\Users\\Wesle\\Desktop\\é‡åŒ–äº¤æ˜“æ„å»º\\å¸‚åœºæ•°æ®åº“\\æ•°æ®åº“\\åŒèŠ±é¡ºæŒ‡æ•°è‡ªç”±æµé€šæ¢æ‰‹ç‡"

                    data = pd.read_csv(filepath + "\\" + code+".csv", index_col=[0])

                    data.index = pd.to_datetime(data.index)

                    Free_Turn_Data = data[['ths_free_turnover_ratio_index']]

                    Free_Turn_Data.columns=[code]

                    return Free_Turn_Data

                Data = Get_Index_Free_Turn_Data(code)

                Data = Data.rolling(Rolling_Mean).mean()

                Final_Date=datetime.strptime(End_Date,'%Y-%m-%d')

                Previous_Date=Final_Date-timedelta(days=365)

                Begin_Date=Previous_Date.strftime('%Y-%m-%d')

                Score = stats.percentileofscore(Data.loc[Begin_Date:End_Date, Data.columns[0]],
                                                Data.loc[End_Date, Data.columns[0]])

                return Score

            Scores = []

            for i in range(0, len(Code_List)):

                try:
                    Score = Get_Last_Percentile_Score(Code_List[i],End_Date)

                    Score = pd.DataFrame(Score, index=[Code_List[i]],
                                            columns=["ç§»åŠ¨å¹³å‡æ¢æ‰‹ç‡åŒºé—´ç™¾åˆ†ä½: " + End_Date])

                    print("æ¢æ‰‹ç‡ç™¾åˆ†ä½è®¡ç®—å®Œæˆç‡ï¼š" + str(i / len(Code_List)))

                    Scores.append(Score)
                
                except:

                    print(Code_List[i]+"å‡ºç°é”™è¯¯")


            Scores = pd.concat(Scores, axis=0)

            return Scores

        Final_Date=datetime.strptime(End_Date,'%Y-%m-%d')

        Previous_Date=Final_Date-timedelta(days=90)

        Begin_Date=Previous_Date.strftime('%Y-%m-%d')
        
        IF=Caculate_Information_Ratio_Windway(Begin_Date,End_Date)

        IF['Information_Ratio']=mstats.winsorize(IF['Information_Ratio'], limits=[0.01, 0.01])

        IF['Information_Ratio'] = zscore(IF['Information_Ratio'])

        Crowdy=Get_Crowdy_Ratio(End_Date)

        IF.loc[:,"æ¢æ‰‹ç‡æ‹¥æŒ¤åº¦"]=Crowdy

        return IF

    # å‡çº¿åç¦»å› å­
    def MA_Deviation_Factor(code, window):
        # æ„å»ºæ–‡ä»¶è·¯å¾„
        file_path = os.path.join(
            'C:\\Users\\Wesle\\Desktop\\é‡åŒ–äº¤æ˜“æ„å»º\\å¸‚åœºæ•°æ®åº“\\æ•°æ®åº“\\åŒèŠ±é¡ºETFè·Ÿè¸ªæŒ‡æ•°é‡ä»·æ•°æ®', code + '.csv')

        # è¯»å–CSVæ–‡ä»¶
        try:
            data = pd.read_csv(file_path)
        except FileNotFoundError:
            print(f"æ–‡ä»¶ {file_path} æœªæ‰¾åˆ°ã€‚")
            return None

        # ç¡®ä¿æ•°æ®æŒ‰æ—¥æœŸå‡åºæ’åˆ—ï¼ˆå¦‚æœæ–‡ä»¶ä¸­ä¸æ˜¯è¿™æ ·çš„è¯ï¼‰
        data['time'] = pd.to_datetime(data['time'])
        data.sort_values('time', inplace=True)

        # è®¡ç®—Næ—¥å‡çº¿
        data[f'{window}day_MA'] = data['close'].rolling(window=window).mean()

        # è®¡ç®—åç¦»å› å­
        data['Factor'] = (data['close'] - data[f'{window}day_MA']) / data[f'{window}day_MA']

        # ç”Ÿæˆè¾“å‡ºçš„DataFrame
        result_df = pd.DataFrame(data={'time': data['time'], 'Factor': data['Factor']})
        result_df.set_index('time', inplace=True)

        return result_df

    def Calculate_MA_Deviation_Factor(end_date, window=250):
        folder_path = 'C:\\Users\\Wesle\\Desktop\\é‡åŒ–äº¤æ˜“æ„å»º\\å¸‚åœºæ•°æ®åº“\\æ•°æ®åº“\\åŒèŠ±é¡ºETFè·Ÿè¸ªæŒ‡æ•°é‡ä»·æ•°æ®'
        files = os.listdir(folder_path)
        results = []

        # è®¡ç®—Næ—¥å‡çº¿åç¦»å› å­å¹¶æ”¶é›†æ•°æ®
        for file in files:

            try:
                if file.endswith('.csv'):
                    code = file.replace('.csv', '')
                    file_path = os.path.join(folder_path, file)
                    try:
                        data = pd.read_csv(file_path)
                    except FileNotFoundError:
                        print(f"æ–‡ä»¶ {file_path} æœªæ‰¾åˆ°ã€‚")
                        continue
                    data['time'] = pd.to_datetime(data['time'])
                    data.sort_values('time', inplace=True)
                    data[f'{window}day_MA'] = data['close'].rolling(window=window).mean()
                    data['Factor'] = (data['close'] - data[f'{window}day_MA']) / data[f'{window}day_MA']
                    factor_on_date = data.loc[data['time'] == pd.to_datetime(end_date), 'Factor']
                    results.append({'Code': code, 'MA_Deviation_Factor': factor_on_date.iloc[
                        0] if not factor_on_date.empty else np.nan})
            except:

                print(file + "å‡ºç°é—®é¢˜")

        # åˆ›å»ºDataFrame
        factor_df = pd.DataFrame(results)
        factor_df.set_index('Code', inplace=True)

        # å»é™¤å¼‚å¸¸å€¼å’Œæ ‡å‡†åŒ–å¤„ç†
        factor_df['MA_Deviation_Factor'] = mstats.winsorize(factor_df['MA_Deviation_Factor'], limits=[0.01, 0.01])
        factor_df['MA_Deviation_Factor'] = (factor_df['MA_Deviation_Factor'] - factor_df[
            'MA_Deviation_Factor'].mean()) / factor_df['MA_Deviation_Factor'].std()

        return factor_df

    #äº¤æ˜“æ³¢åŠ¨å› å­
    def Calculate_Amount_Volume_Std_Factor(end_date, window_size=500):

        def amount_volume_std_factor(df, window):
            df = df.sort_values('time')
            df['amount_std'] = df['amount'].rolling(window).std()
            df['volume_std'] = df['volume'].rolling(window).std()
            df = df.dropna()
            df['amount_factor'] = df[['amount_std']].transform(zscore)
            df['volume_factor'] = df[['volume_std']].transform(zscore)
            df['factor'] = -(df['amount_factor'] + df['volume_factor']) / 2
            return df

        # å¤„ç†æç«¯å€¼çš„å‡½æ•°
        def limit_to_std(x):
            mean = x.mean()
            std = x.std()
            x = x.apply(lambda v: min(max(v, mean - 3 * std), mean + 3 * std))
            return x

        # æ–‡ä»¶å¤¹è·¯å¾„
        folder_path = r'C:\Users\Wesle\Desktop\é‡åŒ–äº¤æ˜“æ„å»º\å¸‚åœºæ•°æ®åº“\æ•°æ®åº“\åŒèŠ±é¡ºETFè·Ÿè¸ªæŒ‡æ•°é‡ä»·æ•°æ®'
        files = os.listdir(folder_path)

        # ç”¨äºå­˜æ”¾æ‰€æœ‰è‚¡ç¥¨æŒ‡å®šæ—¥å› å­å€¼çš„åˆ—è¡¨
        factors_list = []

        # éå†æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰æ–‡ä»¶
        for file in files:
            try:
                file_path = os.path.join(folder_path, file)
                # è¯»å–CSVæ–‡ä»¶
                df = pd.read_csv(file_path)
                
                # è®¡ç®—å› å­å€¼
                df_with_factors = amount_volume_std_factor(df, window_size)
                
                df_with_factors.index = pd.to_datetime(df_with_factors['time'])
                # è·å–æŒ‡å®šæ—¥æœŸçš„å› å­å€¼
                specified_date_factor = df_with_factors.loc[end_date:end_date]
                specified_date_factor = specified_date_factor[['thscode', 'factor']]
                factors_list.append(specified_date_factor)
            except Exception as e:
                print(f"Error processing file {file}: {e}")

        # å°†å› å­å€¼åˆ—è¡¨è½¬æ¢ä¸ºDataFrame
        factors_df = pd.concat(factors_list)

        # å¤„ç†æç«¯å€¼
        factors_df['Amount_Volume_Std_Factor'] = limit_to_std(factors_df['factor'])

        # æ ‡å‡†åŒ–å¤„ç†
        factors_df['Amount_Volume_Std_Factor'] = zscore(factors_df['Amount_Volume_Std_Factor'])

        # å°†è‚¡ç¥¨ä»£ç è®¾ç½®ä¸ºç´¢å¼•
        factors_df.set_index('thscode', inplace=True)

        factors_df = factors_df[['Amount_Volume_Std_Factor']]

        return factors_df

    #æ¢æ‰‹ç‡å˜åŒ–å› å­
    def Caculate_Turnover_Rate_Change_Factor(End_Date,Window1=125,Window2=75):

        def Turnover_Rate_Change_Factor(Code, Window1, Window2):
            # æ ¹æ®è‚¡ç¥¨ä»£ç è®¾ç½®æ–‡ä»¶è·¯å¾„
            file_path = f'C:\\Users\\Wesle\\Desktop\\é‡åŒ–äº¤æ˜“æ„å»º\\å¸‚åœºæ•°æ®åº“\\æ•°æ®åº“\\åŒèŠ±é¡ºæŒ‡æ•°è‡ªç”±æµé€šæ¢æ‰‹ç‡\\{Code}.csv'

            # è¯»å–csvæ–‡ä»¶
            data = pd.read_csv(file_path)
            data['time'] = pd.to_datetime(data['time'])
            data.set_index('time', inplace=True)

            # è®¡ç®—æ»šåŠ¨å¹³å‡æ¢æ‰‹ç‡
            data['rolling_mean_window1'] = data['ths_free_turnover_ratio_index'].rolling(window=Window1).mean()
            data['rolling_mean_window2'] = data['ths_free_turnover_ratio_index'].rolling(window=Window2).mean()

            # è®¡ç®—å› å­å€¼
            data['factor'] = data['rolling_mean_window1'] / data['rolling_mean_window2']

            return data[['factor']]

        # è®¾ç½®æ–‡ä»¶å¤¹è·¯å¾„
        folder_path = 'C:\\Users\\Wesle\\Desktop\\é‡åŒ–äº¤æ˜“æ„å»º\\å¸‚åœºæ•°æ®åº“\\æ•°æ®åº“\\åŒèŠ±é¡ºæŒ‡æ•°è‡ªç”±æµé€šæ¢æ‰‹ç‡'

        # è·å–æ‰€æœ‰çš„æ–‡ä»¶å
        files = os.listdir(folder_path)

        # åˆ›å»ºä¸€ä¸ªç©ºçš„DataFrameæ¥å­˜å‚¨æ‰€æœ‰è‚¡ç¥¨çš„å› å­å€¼
        df_all = pd.DataFrame()

        # å¯¹æ¯ä¸€ä¸ªæ–‡ä»¶è®¡ç®—å› å­å€¼
        for file in files:
            try:
                # è·å–è‚¡ç¥¨ä»£ç 
                code = file.replace('.csv',"")
                # è®¡ç®—å› å­å€¼
                df = Turnover_Rate_Change_Factor(code, Window1, Window2)
                # æå–æŒ‡å®šæ—¥æœŸçš„å› å­å€¼
                factor_value = df.loc[End_Date, 'factor']
                # æ·»åŠ åˆ°df_all
                df_all.loc[code, 'Turnover_Rate_Change_Factor'] = factor_value
            
            except:
                print('å‡ºç°é”™è¯¯è·³è¿‡')

        df_all=df_all.dropna()

        # å»é™¤å¼‚å¸¸å€¼
        df_all['Turnover_Rate_Change_Factor'] = mstats.winsorize(df_all['Turnover_Rate_Change_Factor'], limits=[0.01, 0.01])

        # z-scoreæ ‡å‡†åŒ–
        df_all['Turnover_Rate_Change_Factor'] = zscore(df_all['Turnover_Rate_Change_Factor'])

        return df_all

    #å¤šç©ºå¯¹æ¯”å› å­

    def Calculate_Long_Short_Compare_Change_Factor(date,Window1=30, Window2=15):
            # å®šä¹‰å‡½æ•°è®¡ç®—å› å­å€¼ #
            #å› å­å®šä¹‰å› å­çš„å®šä¹‰ä¸º<é¦–å…ˆè®¡ç®—å¤šç©ºåŠ›é‡å¯¹æ¯”ã€‚åˆ†å­æˆ‘ä»¬ç”¨å¤šå¤´åŠ›é‡ä¸ç©ºå¤´åŠ›é‡ç›¸å‡ï¼Œå³
        # (ğ¶ğ‘™ğ‘œğ‘ ğ‘’ âˆ’ ğ¿ğ‘œğ‘¤) âˆ’ (ğ»ğ‘–ğ‘”â„ âˆ’ ğ¶ğ‘™ğ‘œğ‘ ğ‘’)ï¼Œåˆ†æ¯ä¸ºæœ€é«˜ä»·å‡å»æœ€ä½ä»·ï¼Œä¹Ÿå°±æ˜¯æ—¥å†…ä»·æ ¼åŒº
        # é—´çš„æå€¼ã€‚å†å°†æ‰€å¾—å¤šç©ºåŠ›é‡å¯¹æ¯”ä¹˜ä¸Šå½“æ—¥è¡Œä¸šæˆäº¤é‡ï¼Œå¯å¾—å½“æ—¥å¤šç©ºåŠ›é‡å¯¹æ¯”
        # çš„é‡‘é¢ç»å¯¹å€¼ã€‚
        # æˆ‘ä»¬ç”¨é•¿æœŸæ¯æ—¥å¤šç©ºåŠ›é‡å¯¹æ¯”çš„æŒ‡æ•°åŠ æƒå¹³å‡å€¼ï¼Œå‡å»çŸ­æœŸæ¯æ—¥å¤šç©ºåŠ›é‡å¯¹æ¯”çš„
        # æŒ‡æ•°åŠ æƒå¹³å‡å€¼ï¼Œå¯ä»¥å¾—åˆ°è¿‘æœŸå¤šç©ºåŠ›é‡å¯¹æ¯”ç›¸å¯¹äºé•¿æœŸå¤šç©ºåŠ›é‡å¯¹æ¯”å‡å€¼çš„å˜åŒ–ã€‚
        # å› å­å€¼è¶Šå¤§ï¼Œè¯´æ˜è¿‘æœŸå¤šå¤´ç›¸å¯¹äºç©ºå¤´åŠ›é‡å‡å¼±ï¼›å› å­å€¼è¶Šå°ï¼Œè¯´æ˜è¿‘æœŸå¤šç©ºå¯¹
        # æ¯”åº¦ç›¸å¯¹äºé•¿æœŸåŠ å¤§
            def Long_Short_Compare_Change(Code):
                db_path = r"C:\Users\Wesle\Desktop\é‡åŒ–äº¤æ˜“æ„å»º\å¸‚åœºæ•°æ®åº“\æ•°æ®åº“\åŒèŠ±é¡ºETFè·Ÿè¸ªæŒ‡æ•°é‡ä»·æ•°æ®"
                data = pd.read_csv(os.path.join(db_path, f"{Code}.csv"))
                data['time'] = pd.to_datetime(data['time'])
                data.set_index('time', inplace=True)
                data['LS_Compare'] = data['volume'] * ((data['close'] - data['low']) - (data['high'] - data['close'])) / (data['high'] - data['low'])
                long_term = data['LS_Compare'].ewm(span=Window1).mean()
                short_term = data['LS_Compare'].ewm(span=Window2).mean()
                data['LS_Compare_Change'] = long_term - short_term
                # æ·»åŠ å¤„ç†é€»è¾‘ä»¥æå–ç‰¹å®šæ—¥æœŸçš„å› å­å€¼
                return data.loc[date, 'LS_Compare_Change'] if date in data.index else np.nan

            # å®šä¹‰å‡½æ•°éå†æ‰€æœ‰è‚¡ç¥¨æ–‡ä»¶å¹¶è®¡ç®—å› å­å€¼
            def calc_factor_values():
                db_path = r"C:\Users\Wesle\Desktop\é‡åŒ–äº¤æ˜“æ„å»º\å¸‚åœºæ•°æ®åº“\æ•°æ®åº“\åŒèŠ±é¡ºETFè·Ÿè¸ªæŒ‡æ•°é‡ä»·æ•°æ®"
                codes = [f[:-4] for f in os.listdir(db_path) if f.endswith('.csv')]
                values = [Long_Short_Compare_Change(code) for code in codes]
                df = pd.DataFrame(values, index=codes, columns=['Long_Short_Compare_Change'])
                return df

            # å®šä¹‰å‡½æ•°è¿›è¡Œå› å­å€¼çš„é¢„å¤„ç†
            def preprocess_factor_values(df):
                transformer = QuantileTransformer(output_distribution='normal')
                df['Long_Short_Compare_Change'] = transformer.fit_transform(df[['Long_Short_Compare_Change']])
                return df
            # è®¡ç®—å’Œå¤„ç†å› å­å€¼
            df = calc_factor_values()
            df=df.dropna()
            df = preprocess_factor_values(df)

            return df


    # ROEå˜åŒ–å› å­-30å¤©è°ƒä»“
    def Calculate_Roe_Change_Factor(End_Date,window=120):
        # å®šä¹‰ç›ˆåˆ©é¢„æµ‹æ•°æ®çš„æ–‡ä»¶å¤¹è·¯å¾„
        directory = "C:\\Users\\Wesle\\Desktop\\é‡åŒ–äº¤æ˜“æ„å»º\\å¸‚åœºæ•°æ®åº“\\æ•°æ®åº“\\åŒèŠ±é¡ºETFè·Ÿè¸ªæŒ‡æ•°ä¸€è‡´é¢„æœŸæ•°æ®\\ç›ˆåˆ©é¢„æµ‹ç»¼åˆå€¼"
        
        # è·å–æ–‡ä»¶å¤¹ä¸­æ‰€æœ‰çš„CSVæ–‡ä»¶
        files = [f for f in os.listdir(directory) if f.endswith('.csv')]
        
        # åˆå§‹åŒ–ä¸€ä¸ªç©ºçš„DataFrameç”¨äºå­˜å‚¨ç»“æœ
        result_df = pd.DataFrame(columns=['Code', 'roe_change_factor'])
        
        # éå†æ‰€æœ‰çš„CSVæ–‡ä»¶
        for file in files:
            # ä»æ–‡ä»¶åä¸­è·å–è‚¡ç¥¨ä»£ç ï¼ˆå»æ‰.csvåç¼€ï¼‰
            code = file[:-4]  
            
            # æ„å»ºæ¯åªè‚¡ç¥¨çš„CSVæ–‡ä»¶è·¯å¾„
            filename = directory + "\\" + file
            
            # è¯»å–CSVæ–‡ä»¶
            df = pd.read_csv(filename)
            
            # æŒ‰æ—¶é—´æ’åº
            df = df.sort_values(by='time')
            
            # å°†æ—¶é—´è®¾ç½®ä¸ºç´¢å¼•
            df.set_index('time', inplace=True)
            
            # è®¡ç®—é¢„æœŸ ROE å˜åŒ–å› å­
            df['roe_change_factor'] = (df['ths_fore_roe_mean_index'] / df['ths_fore_roe_mean_index'].shift(window)) - 1
            
            # å¦‚æœæŒ‡å®šæ—¥æœŸçš„æ•°æ®ä¸å­˜åœ¨ï¼Œè·³è¿‡æ­¤æ¬¡å¾ªç¯
            if End_Date not in df.index:
                continue
            
            # æå–æŒ‡å®šæ—¥æœŸçš„å› å­å€¼
            factor = df.loc[End_Date, 'roe_change_factor']
            
            # å¦‚æœå› å­å€¼æ˜¯NaNï¼Œè·³è¿‡æ­¤æ¬¡å¾ªç¯
            if pd.isnull(factor):
                continue
            
            # å°†ç»“æœæ·»åŠ åˆ°ç»“æœDataFrameä¸­
            result_df = result_df.append({'Code': code, 'roe_change_factor': factor}, ignore_index=True)
        
        qt = QuantileTransformer(output_distribution='normal')

        # å¯¹æ•°æ®è¿›è¡Œè½¬æ¢
        transformed_factors = qt.fit_transform(result_df['roe_change_factor'].values.reshape(-1, 1))

        # åˆ›å»ºä¸€ä¸ªæ–°çš„DataFrameæ¥å­˜å‚¨ç»“æœ
        result = pd.DataFrame(transformed_factors, index=result_df['Code'], columns=['roe_change_factor'])

        # æ›´æ”¹åˆ—åä¸º'Roe_Change_Factor'
        result.columns = ['Roe_Change_Factor']
        
        return result

        
        #è¶…è·Œ850å‡çº¿å› å­
    #ERSå˜åŒ–å› å­-20å¤©è°ƒä»“
    def Calculate_Eps_Change_Factor(date,window=140) -> pd.DataFrame:

        # æ•°æ®çš„ä¿å­˜åœ°å€
        data_dir = "C:\\Users\\Wesle\\Desktop\\é‡åŒ–äº¤æ˜“æ„å»º\\å¸‚åœºæ•°æ®åº“\\æ•°æ®åº“\\åŒèŠ±é¡ºETFè·Ÿè¸ªæŒ‡æ•°ä¸€è‡´é¢„æœŸæ•°æ®\\ç›ˆåˆ©é¢„æµ‹ç»¼åˆå€¼\\"

        # åˆå§‹åŒ–ä¸€ä¸ªç©ºçš„ DataFrame æ¥å­˜å‚¨æ‰€æœ‰è‚¡ç¥¨çš„ç»“æœ
        results = pd.DataFrame()

        # éå†æ¯ä¸ªæ–‡ä»¶
        for file in os.listdir(data_dir):
            if file.endswith(".csv"):
                # è®¡ç®—æ¯åªè‚¡ç¥¨çš„å› å­å€¼
                data = pd.read_csv(os.path.join(data_dir, file), parse_dates=['time'])
                data.set_index('time', inplace=True)
                data['EPS Change'] = data['ths_fore_eps_index'].pct_change(periods=window)

                # æå–æŒ‡å®šæ—¥æœŸçš„å› å­å€¼
                factor_value = data.loc[date, 'EPS Change'] if date in data.index else None

                # æ·»åŠ åˆ°ç»“æœä¸­
                results.loc[file[:-4], 'é¢„æœŸ EPSç™¾åˆ†æ¯”å˜åŒ–å› å­'] = factor_value

        # Winsorize å¼‚å¸¸å€¼
        results['é¢„æœŸ EPSç™¾åˆ†æ¯”å˜åŒ–å› å­'] = mstats.winsorize(results['é¢„æœŸ EPSç™¾åˆ†æ¯”å˜åŒ–å› å­'], limits=[0.05, 0.05])

        results.dropna(inplace=True)

        # z-scoreæ ‡å‡†åŒ–å¤„ç†
        results['é¢„æœŸ EPSç™¾åˆ†æ¯”å˜åŒ–å› å­'] = zscore(results['é¢„æœŸ EPSç™¾åˆ†æ¯”å˜åŒ–å› å­'])

        results.rename(columns={'é¢„æœŸ EPSç™¾åˆ†æ¯”å˜åŒ–å› å­': 'EPS_Change_Factor'}, inplace=True)

        return results

    def Calculate_ROE_Two_MA_Deviation_Factor(End_Date,window1=120,window2=90):


    #æ³¢åŠ¨ç‡å æ¯”å› å­
     def Downside_Volatility_Ratio_MA_Factor(Code, window1, window2):
        # ä»CSVæ–‡ä»¶ä¸­è¯»å–æ•°æ®
        file_path = os.path.join(
            "C:\\Users\\Wesle\\Desktop\\é‡åŒ–äº¤æ˜“æ„å»º\\å¸‚åœºæ•°æ®åº“\\æ•°æ®åº“\\åŒèŠ±é¡ºETFè·Ÿè¸ªæŒ‡æ•°é‡ä»·æ•°æ®",
            f"{Code}.csv")
        data = pd.read_csv(file_path)

        # ç¡®ä¿æ•°æ®æŒ‰æ—¶é—´æ’åº
        data['time'] = pd.to_datetime(data['time'])
        data.sort_values('time', inplace=True)

        # è®¡ç®—æ—¥æ”¶ç›Šç‡
        data['returns'] = data['close'].pct_change()

        # è®¡ç®—æ€»æ³¢åŠ¨ç‡
        data['total_volatility'] = data['returns'].rolling(window=window1).std()

        # è®¡ç®—ä¸‹è¡Œæ³¢åŠ¨ç‡
        downside_returns = data['returns'].apply(lambda x: x if x < 0 else 0)
        data['downside_volatility'] = downside_returns.rolling(window=window1).std()

        # è®¡ç®—ä¸‹è¡Œæ³¢åŠ¨ç‡å æ¯”å› å­
        data['downside_vol_ratio'] = data['downside_volatility'] / data['total_volatility']

        # è®¡ç®—ç§»åŠ¨å¹³å‡å€¼
        data['downside_vol_ratio_MA'] = data['downside_vol_ratio'].rolling(window=window2).mean()
        #è®¡ç®—å› å­å€¼ï¼Œå æ¯”è¶Šå°åˆ†æ•°è¶Šé«˜
        data['downside_vol_ratio_MA'] = 1 - data['downside_vol_ratio_MA']
        # ä»…ä¿ç•™éœ€è¦çš„åˆ—
        result = data[['time', 'downside_vol_ratio_MA']].set_index('time')

        return result

    def Caculate_Downside_Volatility_Ratio_MA_Factor(End_Date, window1=120, window2=25):
        def Downside_Volatility_Ratio_MA_Factor(Code, window1, window2):
            # ä»CSVæ–‡ä»¶ä¸­è¯»å–æ•°æ®
            file_path = os.path.join(
                "C:\\Users\\Wesle\\Desktop\\é‡åŒ–äº¤æ˜“æ„å»º\\å¸‚åœºæ•°æ®åº“\\æ•°æ®åº“\\åŒèŠ±é¡ºETFè·Ÿè¸ªæŒ‡æ•°é‡ä»·æ•°æ®",
                f"{Code}.csv")
            data = pd.read_csv(file_path)

            # ç¡®ä¿æ•°æ®æŒ‰æ—¶é—´æ’åº
            data['time'] = pd.to_datetime(data['time'])
            data.sort_values('time', inplace=True)

            # è®¡ç®—æ—¥æ”¶ç›Šç‡
            data['returns'] = data['close'].pct_change()

            # è®¡ç®—æ€»æ³¢åŠ¨ç‡
            data['total_volatility'] = data['returns'].rolling(window=window1).std()

            # è®¡ç®—ä¸‹è¡Œæ³¢åŠ¨ç‡
            downside_returns = data['returns'].apply(lambda x: x if x < 0 else 0)
            data['downside_volatility'] = downside_returns.rolling(window=window1).std()

            # è®¡ç®—ä¸‹è¡Œæ³¢åŠ¨ç‡å æ¯”å› å­
            data['downside_vol_ratio'] = data['downside_volatility'] / data['total_volatility']

            # è®¡ç®—ç§»åŠ¨å¹³å‡å€¼
            data['downside_vol_ratio_MA'] = data['downside_vol_ratio'].rolling(window=window2).mean()
            # è®¡ç®—å› å­å€¼ï¼Œå æ¯”è¶Šå°åˆ†æ•°è¶Šé«˜
            data['downside_vol_ratio_MA'] = 1 - data['downside_vol_ratio_MA']
            # ä»…ä¿ç•™éœ€è¦çš„åˆ—
            result = data[['time', 'downside_vol_ratio_MA']].set_index('time')

            return result



            return pd.Series(mstats.winsorize(series, limits=limits), index=series.index)

        def remove_extreme_values(df, column, num_std=3):
            mean_val = df[column].mean()
            std_val = df[column].std()
            lower_bound = mean_val - num_std * std_val
            upper_bound = mean_val + num_std * std_val
            df[column] = df[column].clip(lower_bound, upper_bound)
            return df

        directory = "C:\\Users\\Wesle\\Desktop\\é‡åŒ–äº¤æ˜“æ„å»º\\å¸‚åœºæ•°æ®åº“\\æ•°æ®åº“\\åŒèŠ±é¡ºETFè·Ÿè¸ªæŒ‡æ•°é‡ä»·æ•°æ®"
        factors = {}
        for filename in os.listdir(directory):
            try:
                if filename.endswith(".csv"):
                    code = filename[:-4]
                    df = Downside_Volatility_Ratio_MA_Factor(code, window1, window2)
                    factors[code] = df.loc[End_Date, 'downside_vol_ratio_MA']
            except Exception as e:
                print(f'å‡ºç°é”™è¯¯è·³è¿‡: {e}')

        df_factors = pd.DataFrame.from_dict(factors, orient='index', columns=['Downside_Volatility_Ratio_MA_Factor'])

        # ä½¿ç”¨3ÏƒåŸåˆ™å»é™¤æå€¼
        df_factors = remove_extreme_values(df_factors, 'Downside_Volatility_Ratio_MA_Factor')

        # ä½¿ç”¨Z-scoreæ ‡å‡†åŒ–å¤„ç†
        df_factors['Downside_Volatility_Ratio_MA_Factor'] = zscore(df_factors['Downside_Volatility_Ratio_MA_Factor'])
            
        return df_factors




def Mul_Factor_Strategy(End_Date):

    ETF=ETF_Strategy
    #åŠ¨é‡å› å­
    MTSS=ETF.Caculate_Momentum_Term_Spread_Score(End_Date)
    #ï¼ˆ10å¤©ï¼‰
    SOMF=ETF.Caculate_Second_Order_Momentum_Factor('2024-03-29')

    MA=ETF.Calculate_MA_Deviation_Factor(End_Date)
    
    Momentum=pd.concat([MTSS,MA],axis=1)

    Momentum.loc[:,'Total']=Momentum.loc[:,"Momentum_Term_Spread"]+ Momentum.loc[:,"MA_Deviation_Factor"] 
    
    Momentum=Momentum.dropna()

    Momentum=Momentum[['Total']]

    Momentum.columns=['Momentum']

    Momentum=zscore(Momentum)    

    #äº¤æ˜“æ³¢åŠ¨å› å­

    AV_STD_Factor=ETF.Calculate_Amount_Volume_Std_Factor(End_Date)

    AV_STD_Factor.columns=['Trade_Std']

    #æ¢æ‰‹ç‡å˜åŒ–

    Turnover=ETF.Caculate_Turnover_Rate_Change_Factor(End_Date)
    Turnover=Turnover.dropna()

    #å¤šç©ºå¯¹æ¯”ï¼ˆ10å¤©è°ƒä»“)

    LSCC=ETF.Calculate_Long_Short_Compare_Change_Factor('2024-03-29')
    LS_Total=LSCC

    #ä¸€è‡´é¢„æœŸå˜åŒ–å› å­

    Expected=ETF.Caculate_Expected_Data_MoM(End_Date)
    Expected.columns=['Expected_MOM']
    Expected=Expected.dropna()

    ROE_Change=ETF.Calculate_Roe_Change_Factor(End_Date)
    ROE_Change.columns=['ROE_Change']
    ROE_Change=ROE_Change.dropna()

    EPS_Change=ETF.Calculate_Eps_Change_Factor(End_Date)
    EPS_Change.columns=['EPS_Change']
    EPS_Change=EPS_Change.dropna()

    Expected_Change_Total=pd.concat([ROE_Change,EPS_Change,Expected],axis=1)
    Expected_Change_Total.loc[:,"Expected_Change_Total"]=(Expected_Change_Total.loc[:,"ROE_Change"]\
                                                          +Expected_Change_Total.loc[:,"EPS_Change"]\
                                                            +Expected_Change_Total.loc[:,"Expected_MOM"])
    Expected_Change_Total=Expected_Change_Total[['Expected_Change_Total']]
    Expected_Change_Total=Expected_Change_Total.dropna()
    Expected_Change_Total=zscore(Expected_Change_Total)

    #ä¸‹è¡Œæ³¢åŠ¨ç‡å æ¯”å› å­
    Downside_Volatility_Ratio_MA_Factor=ETF.Caculate_Downside_Volatility_Ratio_MA_Factor(End_Date)

    #æ±‡æ€»

    Total_Factor=pd.concat([Momentum,AV_STD_Factor,Turnover,LS_Total,Expected_Change_Total,Downside_Volatility_Ratio_MA_Factor,SOMF],axis=1)

    Total_Factor.loc[:,"Sum"]=Total_Factor.loc[:,"Momentum"]\
    +Total_Factor.loc[:,"Trade_Std"]+Total_Factor.loc[:,"Turnover_Rate_Change_Factor"]\
    +Total_Factor.loc[:,"Long_Short_Compare_Change"]+Total_Factor.loc[:,"Expected_Change_Total"]\
    +Total_Factor.loc[:,"Downside_Volatility_Ratio_MA_Factor"]+Total_Factor.loc[:,"Second_Order_Momentum_Factor"]

    Total_Factor=Total_Factor.sort_values(by='Sum',ascending=False)

    os.chdir(r'C:\Users\Wesle\Desktop\é‡åŒ–äº¤æ˜“æ„å»º\ETFè½®åŠ¨ç­–ç•¥\ETFè½®åŠ¨ç­–ç•¥ç¨‹åº\result')
    Total_Factor.to_excel('é‡ä»·å¤šå› å­é€‰è‚¡.xlsx')

    return Total_Factor



class select_invest_target():

    def Select_ETF_and_Build_Portfilo(self):

        Dirc=pd.read_excel(r'C:\Users\Wesle\Desktop\é‡åŒ–äº¤æ˜“æ„å»º\ETFè½®åŠ¨ç­–ç•¥\ETFè½®åŠ¨ç­–ç•¥ç¨‹åº\result'+"\\é‡ä»·å¤šå› å­é€‰è‚¡.xlsx",index_col=[0])

        #é€‰å‡ºå‰30

        Top_30=Dirc.iloc[:31,:]

        #é€‰å‡ºå¯¹åº”çš„ETFä»£ç å’ŒæŒ‡æ•°

        Top_30_Code=Top_30.index.to_list()

        #å¯¹åº”ETFåç§°æ–‡æ¡£

        ETF_Name=pd.read_excel(r'C:\Users\Wesle\Desktop\é‡åŒ–äº¤æ˜“æ„å»º\ETFè½®åŠ¨ç­–ç•¥\ETFè½®åŠ¨ç­–ç•¥ç¨‹åº\result'+'\\ETFå¯¹åº”åç§°.xlsx')

        ETF_Name.index=ETF_Name.loc[:,"è·Ÿè¸ªæŒ‡æ•°ä»£ç "]

        ETF_Codes=[]

        ETF_Names=[]

        for i in range(0,len(Top_30_Code)):
            
            try:

                Index_Code=Top_30_Code[i]

                ETF_Match_Code=ETF_Name.loc[[Index_Code]]

                if len(ETF_Match_Code.loc[:,"è¯¯å·®"])>1:

                    ETF_Match_Code=ETF_Match_Code.sort_values(by='è¯¯å·®',ascending=True)

                    ETF_Code=ETF_Match_Code.iloc[0,0]

                    Name=ETF_Match_Code.iloc[0,1]

                else:
                    
                    ETF_Code=ETF_Match_Code.iloc[0,0]

                    Name=ETF_Match_Code.iloc[0,1]

                ETF_Codes.append(ETF_Code)

                ETF_Names.append(Name)
            
            except:

                print(Top_30_Code[i])
        
        Result=pd.DataFrame(ETF_Codes,index=Top_30_Code,columns=["ETFå¯¹åº”æŒ‡æ•°"])

        Result.loc[:,"ETF_Name"]=ETF_Names

        Final_Result=pd.merge(Result,Dirc,right_index=True,left_index=True)

        os.chdir(r'C:\Users\Wesle\Desktop\é‡åŒ–äº¤æ˜“æ„å»º\ETFè½®åŠ¨ç­–ç•¥\ETFè½®åŠ¨ç­–ç•¥ç¨‹åº\result')

        Final_Result.to_excel('é‡ä»·ETFç»„åˆç»“æœå‰30.xlsx')

        return Final_Result

    def Caculate_Port_Corr(self,index_code_list,window):
        
        path=r'C:\Users\Wesle\Desktop\é‡åŒ–äº¤æ˜“æ„å»º\å¸‚åœºæ•°æ®åº“\æ•°æ®åº“\åŒèŠ±é¡ºETFè·Ÿè¸ªæŒ‡æ•°é‡ä»·æ•°æ®'

        port=[]
        for i in index_code_list:

            data=pd.read_csv(path+'\\'+i+'.csv',index_col=[0])
            data.index=pd.to_datetime(data.index)
            close=data[['close']]
            close.columns=[i]
            port.append(close)
        
        port=pd.concat(port,axis=1)
        port=port.dropna()
        port=port.iloc[-window:,:]
        port_pct=port.pct_change()
        corr=port_pct.corr()

        return corr


ETF=ETF_Strategy

smf=ETF.second_order_momentum_factor()

# sit=select_invest_target()
# etf_result=sit.Select_ETF_and_Build_Portfilo()

# code_list=['931008.CSI','931166.CSI','931402.CSI','931187.CSI','931052.CSI','399998.SZ']

# Corr=sit.Caculate_Port_Corr(code_list,250)

